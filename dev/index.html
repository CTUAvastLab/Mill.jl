<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Mill.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="Mill.jl logo"/></a><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#What-is-Multiple-instance-learning-(MIL)-problem?"><span>What is Multiple instance learning (MIL) problem?</span></a></li><li><a class="tocitem" href="#Relation-to-Graph-Neural-Networks"><span>Relation to Graph Neural Networks</span></a></li><li><a class="tocitem" href="#Difference-to-sequences"><span>Difference to sequences</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="examples/simple/">Simple</a></li><li><a class="tocitem" href="examples/advanced/">Advanced</a></li><li><a class="tocitem" href="examples/graphs/">GNN in 16 lines</a></li><li><a class="tocitem" href="examples/dag/">DAGs</a></li></ul></li><li><span class="tocitem">Architecture of Mill</span><ul><li><a class="tocitem" href="architecture/overview/">Overview</a></li><li><a class="tocitem" href="architecture/reflectin/">ReflectInModel</a></li><li><a class="tocitem" href="architecture/strings/">Handling strings</a></li><li><a class="tocitem" href="architecture/aggregation/">Aggregations</a></li><li><a class="tocitem" href="architecture/missing/">Missing values</a></li><li><a class="tocitem" href="architecture/custom/">Custom Nodes</a></li></ul></li><li><span class="tocitem">Helper tools</span><ul><li><a class="tocitem" href="tools/hierarchical/">HierarichalUtils.jl</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pevnak/Mill.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Mill.jl"><a class="docs-heading-anchor" href="#Mill.jl">Mill.jl</a><a id="Mill.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Mill.jl" title="Permalink"></a></h1><p>Mill.jl is a library build on top of <code>Flux.jl</code> aimed to flexibly prototype <em>hierarchical multi-instance learning</em> models as described in <a href="#Pevny2018a">Tomáš Pevný , Petr Somol  (2017)</a> and  <a href="#Pevny2018b">Tomáš Pevný , Petr Somol  (2016)</a></p><h2 id="What-is-Multiple-instance-learning-(MIL)-problem?"><a class="docs-heading-anchor" href="#What-is-Multiple-instance-learning-(MIL)-problem?">What is Multiple instance learning (MIL) problem?</a><a id="What-is-Multiple-instance-learning-(MIL)-problem?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-Multiple-instance-learning-(MIL)-problem?" title="Permalink"></a></h2><p>Why should I care about MIL problems? Since the seminal paper of Ronald Fisher, the majority of machine learning problems deals with a problem shown below, </p><img src="assets/iris.svg" alt="Iris" class="center"/><p>where the input sample <span>$x$</span> is a vector (or more generally a tensor) of a fixed dimension, alteranativelly a sequence. </p><p>The consequence is that if we want to use a more elaborate description of iris above, for example we wish to describe each of its leaf, blossoms, and stem, we will have a hard time, because every flower has different number of them. This means that to use the usual &quot;fix dimension&quot; paradigm, we have to either use features from a single blossom and single leaf, or aggregate descriptions of their sets, such that the output has a fixed dimension. This is clearly undesirable. We wish a framework that can flexibly and automatically and seamlessly deals with these sets, sets of sets, and cartesian product. </p><p>In <strong>Multiple instance learning</strong> the sample <span>$x$</span> is a set of vectors (or matrices) <span>$\{x_1,\ldots,x_l\}$</span> with <span>$x_i \in R^d$</span>, which means that order does not matter, and which is also the feature making MIL problems different from sequences. The multi-instance problems have been introduced in by Tom Diettrich in <a href="#Dietterich1997">Thomas G. Dietterich , Richard H. Lathrop , Tomás Lozano-Pérez  (1997)</a> in 1997, and extended and generalized in a series of works <a href="#Pevny2018a">Tomáš Pevný , Petr Somol  (2017)</a>, <a href="#Pevny2018b">Tomáš Pevný , Petr Somol  (2016)</a>, <a href="#Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019)</a>. The most comprehensive introduction known to authors is <a href="#Mandlik2020">Šimon Mandlík  (2020)</a></p><p>The <strong>Hierarchical Multiple instance learning</strong> would approach the problem of iris classification as outlined below.</p><img src="assets/iris2.svg" alt="Iris (MIL)" class="center"/><p>It will describe each leaf by a vector implying that all leaves are described by a set of vectors. The same will be done for blossoms (the set will be different of course). Note that such description allows each flower to have a different numbers of each entity. Finally, there will be a single vector describing a stem, since there is only one.</p><p>How does the MIL copes with variability in number of flowers and leafs (in MIL parlance they are called instances and their set is called a bag)? For each MIL problem, there are two feed-forward neural networks with element-wise aggregation operator like <code>mean</code> (or <code>maximum</code>) sandwiched between them. Denoting those feed-forward networks (FFN) by  <span>$f_1$</span>  and <span>$f_2$</span>, the output of a bag calculated is calculated as <span>$f_2 \left\(\frac{1}{l}\sum_{i=1}^l f_1(x_i) \right\)$</span>, where we have used <code>mean</code> as an aggregation function. In <a href="#Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019)</a>, authors have further extended the universal approximation theorem to MIL problems, their Cartesian products, and nested  MIL problems, i.e. a case where instances of one bag are in fact bags. </p><p>This means that the flower in the above Iris example would be described by one bag describing leafs, another bag describing blossoms, and a vector describing stem. The HMIL model would have two FFNs to convert set of leafs to a single vector, another set of two FFNs to convert set of blossoms to a single vector. These two outputs would be concatenated with a description of a stem, which would be fed to yet another FFN providing the final classifications. And since whole scheme is differentiable, we can use standard SGD to optimize all FFNs together using only labels on the level of output.</p><p>The Mill library simplifies implementation of machine learning problems with (H)MIL representation. In theory, it can represent any problem that can be written represented in JSONs. That is why we have created a separate tool, JsonGrinder, which helps to Mill your JSONs.</p><h2 id="Relation-to-Graph-Neural-Networks"><a class="docs-heading-anchor" href="#Relation-to-Graph-Neural-Networks">Relation to Graph Neural Networks</a><a id="Relation-to-Graph-Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Relation-to-Graph-Neural-Networks" title="Permalink"></a></h2><p>HMIL problems can be seen as a special subset of general graphs. They differ in two important ways</p><ul><li>In general graphs, vertices are of a small number of semantic type, whereas in HMIL problems, the number of semantic types of vertices is much higher (it is helpful to think about HMIL problems as about those for which JSON is a natural representation).</li><li>The computational graph of HMIL is a <strong>tree</strong>, which implies that there exist an efficient inference. Contrary, in general graphs (with loops) there is no efficient inference and one has to resort to message passing (Loopy belief propagation).</li><li>One update message in <strong>loopy belief propagation</strong> can be viewed as a MIL problem, as it has to produce a vector based on infomation inthe neighborhood, which can contain arbitrary number of vertices.</li></ul><h2 id="Difference-to-sequences"><a class="docs-heading-anchor" href="#Difference-to-sequences">Difference to sequences</a><a id="Difference-to-sequences-1"></a><a class="docs-heading-anchor-permalink" href="#Difference-to-sequences" title="Permalink"></a></h2><p>The major difference is that sequence does not matter. This means that if a sequence <span>$(a,b,c)$</span> should be treated as a set, then the output of a function <code>f</code> should be the same for any permutation, i.e. <span>$f(abc) = f(cba) = f(bac) =\ldots$</span>. This property has a dramatic consequence of the computational complexity. Sequences are typically modeled using Recurrent Neural Networks (RNN), where the output is calculated as <span>$f(abc) = g(a, g(b, g(c)))$</span> (with a slight abuse of a notation). During optimization, a gradient of <span>$g$</span> needs to be calculated recursively, giving raise to infamous vanishing / expanding gradient. In constrast, in MIL calculates the output as $ f(\frac{1}{3}(g(a) + g(b) + g(c)))$ (slightly abusing notation again), which means that the gradient of <span>$g$</span> is calculated in parallel and not recurrently. </p><p>A more detailed overview of this subject can be found in <a href="#Mandlik2020">Šimon Mandlík  (2020)</a>.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><dl><dt>Pevny2018a</dt>
<dd>
  <div id="Pevny2018a">Tomáš Pevný , Petr Somol  (2017), <a href="https://arxiv.org/abs/1703.02868">Discriminative models for multi-instance problems with tree-structure</a>, arXiv:1703.02868 [].</a>
</dd><dt>Pevny2018b</dt>
<dd>
  <div id="Pevny2018b">Tomáš Pevný , Petr Somol  (2016), <a href="https://arxiv.org/abs/1609.07257">Using Neural Network Formalism to Solve Multiple-Instance Problems</a>, arXiv:1609.07257 [].</a>
</dd><dt>Dietterich1997</dt>
<dd>
  <div id="Dietterich1997">Thomas G. Dietterich , Richard H. Lathrop , Tomás Lozano-Pérez  (1997), <a href="https://doi.org/https://doi.org/10.1016/S0004-3702(96)00034-3">Solving the multiple instance problem with axis-parallel rectangles</a>, Artificial Intelligence, 89(1), 31 - 71, 1997.</a>
</dd><dt>Zaheer2018</dt>
<dd>
  <div id="Zaheer2018">Manzil Zaheer , Satwik Kottur , Siamak Ravanbakhsh , Barnabás Póczos , Ruslan Salakhutdinov , Alexander J. Smola  (2017), <a href="https://arxiv.org/abs/1703.06114">Deep Sets</a>, arXiv:1703.06114 [].</a>
</dd><dt>Mandlik2020</dt>
<dd>
  <div id="Mandlik2020">Šimon Mandlík  (2020), <a href="">Mapping the Internet: Modelling Entity Interactions in Complex Heterogeneous Networks</a>, Master's thesis, Czech Technical University, 2020.</a>
</dd><dt>Pevny2019</dt>
<dd>
  <div id="Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019), <a href="https://arxiv.org/abs/1906.00764">Approximation capability of neural networks on spaces of probability measures and tree-structured domains</a>, arXiv:1906.00764 [].</a>
</dd>
</dl></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="examples/simple/">Simple »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 14 December 2020 10:51">Monday 14 December 2020</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

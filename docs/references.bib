@article{Pevny2018a,
    author    = {Tomáš Pevný and Petr Somol},
    title     = {Discriminative models for multi-instance problems with tree-structure},
    journal   = {CoRR},
    volume    = {abs/1703.02868},
    year      = {2017},
    url       = {http://arxiv.org/abs/1703.02868},
    archivePrefix = {arXiv},
    eprint    = {1703.02868},
    timestamp = {Mon, 13 Aug 2018 16:48:14 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/PevnyS17.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Pevny2018b,
    author    = {Tomáš Pevný and Petr Somol},
    title     = {Using Neural Network Formalism to Solve Multiple-Instance Problems},
    journal   = {CoRR},
    volume    = {abs/1609.07257},
    year      = {2016},
    url       = {http://arxiv.org/abs/1609.07257},
    archivePrefix = {arXiv},
    eprint    = {1609.07257},
    timestamp = {Mon, 13 Aug 2018 16:48:26 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/PevnyS16.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Pevny2019,
    author    = {Tomáš Pevný and Vojtěch Kovařík},
    title     = {Approximation capability of neural networks on spaces of probability
                 measures and tree-structured domains},
    journal   = {CoRR},
    volume    = {abs/1906.00764},
    year      = {2019},
    url       = {http://arxiv.org/abs/1906.00764},
    archivePrefix = {arXiv},
    eprint    = {1906.00764},
    timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/abs-1906-00764.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Pevny2020,
    author = {Tomáš Pevný and Marek Dědič},
    abstract = {In many interesting cases, the application of machine learning is hindered by data having a complicated structure stimulated by a structured file-formats like JSONs, XMLs, or ProtoBuffers, which is non-trivial to convert to a vector / matrix. Moreover, since the structure frequently carries a semantic meaning, reflecting it in the machine learning model should improve the accuracy but more importantly it facilitates the explanation of decisions and the model. This paper demonstrates on the identification of infected computers in the computer network from their HTTP traffic, how to achieve this reflection using recent progress in multiple-instance learning. The proposed model is compared to complementary approaches from the prior art, the first relying on human-designed features and the second on automatically learned features through convolution neural networks. In a challenging scenario measuring accuracy only on unseen domains/malware families, the proposed model is superior to the prior art while providing a valuable feedback to the security researchers. We believe that the proposed framework will found applications elsewhere even beyond the field of security.},
    archivePrefix = {arXiv},
    arxivId = {2002.04059},
    eprint = {2002.04059},
    month = {feb},
    title = {{Nested Multiple Instance Learning in Modelling of HTTP network traffic}},
    url = {http://arxiv.org/abs/2002.04059},
    year = {2020}
}

@article{Dietterich1997,
    title = "Solving the multiple instance problem with axis-parallel rectangles",
    journal = "Artificial Intelligence",
    volume = "89",
    number = "1",
    pages = "31 - 71",
    year = "1997",
    issn = "0004-3702",
    doi = "https://doi.org/10.1016/S0004-3702(96)00034-3",
    url = "http://www.sciencedirect.com/science/article/pii/S0004370296000343",
    author = "Thomas G. Dietterich and Richard H. Lathrop and Tomás Lozano-Pérez",
    keywords = "Machine learning, Drug design, Structure-activity relationships",
    abstract = "The multiple instance problem arises in tasks where the training examples are ambiguous: a single example object may have many alternative feature vectors (instances) that describe it, and yet only one of those feature vectors may be responsible for the observed classification of the object. This paper describes and compares three kinds of algorithms that learn axis-parallel rectangles to solve the multiple instance problem. Algorithms that ignore the multiple instance problem perform very poorly. An algorithm that directly confronts the multiple instance problem (by attempting to identify which feature vectors are responsible for the observed classifications) performs best, giving 89% correct predictions on a musk odor prediction task. The paper also illustrates the use of artificial data to debug and compare these algorithms."
}

@article{Zaheer2018,
    author    = {Manzil Zaheer and
                 Satwik Kottur and
                 Siamak Ravanbakhsh and
                 Barnabás Póczos and
                 Ruslan Salakhutdinov and
                 Alexander J. Smola},
    title     = {Deep Sets},
    journal   = {CoRR},
    volume    = {abs/1703.06114},
    year      = {2017},
    url       = {http://arxiv.org/abs/1703.06114},
    archivePrefix = {arXiv},
    eprint    = {1703.06114},
    timestamp = {Mon, 13 Aug 2018 16:46:16 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/ZaheerKRPSS17.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@mastersthesis{Mandlik2020,
    author = {Šimon Mandlík and Tomáš Pevný},
    school = "Czech Technical University",
    title = "Mapping the Internet: Modelling Entity Interactions in Complex Heterogeneous Networks",
    note = "\url{https://dspace.cvut.cz/handle/10467/87851?locale-attribute=en}",
    year = "2020"
}

@article{Fisher1936,
    title={The use of multiple measurements in taxonomic problems},
    author={Fisher, Ronald A},
    journal={Annals of eugenics},
    volume={7},
    number={2},
    pages={179--188},
    year={1936},
    publisher={Wiley Online Library}
}

@article{Kraus2015,
    abstract = {Convolutional neural networks (CNN) have achieved state of the art performance on both classification and segmentation tasks. Applying CNNs to microscopy images is challenging due to the lack of datasets labeled at the single cell level. We extend the application of CNNs to microscopy image classification and segmentation using multiple instance learning (MIL). We present the adaptive Noisy-AND MIL pooling function, a new MIL operator that is robust to outliers. Combining CNNs with MIL enables training CNNs using full resolution microscopy images with global labels. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in CNNs. We show that training MIL CNNs end-to-end outperforms several previous methods on both mammalian and yeast microscopy images without requiring any segmentation steps.},
    archivePrefix = {arXiv},
    arxivId = {1511.05286},
    author = {Kraus, Oren Z. and Ba, Lei Jimmy and Frey, Brendan},
    doi = {10.1093/bioinformatics/btw252},
    eprint = {1511.05286},
    month = {nov},
    title = {{Classifying and Segmenting Microscopy Images Using Convolutional Multiple Instance Learning}},
    url = {http://arxiv.org/abs/1511.05286 http://dx.doi.org/10.1093/bioinformatics/btw252},
    year = {2015}
}

@inproceedings{Gulcehre2014,
    abstract = {In this paper we propose and investigate a novel nonlinear unit, called L p unit, for deep neural networks. The proposed L p unit receives signals from several projections of a subset of units in the layer below and computes a normalized L p norm. We notice two interesting interpretations of the L p unit. First, the proposed unit can be understood as a generalization of a number of conventional pooling operators such as average, root-mean-square and max pooling widely used in, for instance, convolutional neural networks (CNN), HMAX models and neocognitrons. Furthermore, the L p unit is, to a certain degree, similar to the recently proposed maxout unit [13] which achieved the state-of-the-art object recognition results on a number of benchmark datasets. Secondly, we provide a geometrical interpretation of the activation function based on which we argue that the L p unit is more efficient at representing complex, nonlinear separating boundaries. Each L p unit defines a superelliptic boundary, with its exact shape defined by the order p. We claim that this makes it possible to model arbitrarily shaped, curved boundaries more efficiently by combining a few L p units of different orders. This insight justifies the need for learning different orders for each unit in the model. We empirically evaluate the proposed L p units on a number of datasets and show that multilayer perceptrons (MLP) consisting of the L p units achieve the state-of-the-art results on a number of benchmark datasets. Furthermore, we evaluate the proposed L p unit on the recently proposed deep recurrent neural networks (RNN).},
    address = {Berlin, Heidelberg},
    author = {Gulcehre, Caglar and Cho, Kyunghyun and Pascanu, Razvan and Bengio, Yoshua},
    booktitle = {Mach. Learn. Knowl. Discov. Databases},
    editor = {Calders, Toon and Esposito, Floriana and H{\"{u}}llermeier, Eyke and Meo, Rosa},
    isbn = {978-3-662-44848-9},
    pages = {530--546},
    publisher = {Springer Berlin Heidelberg},
    title = {{Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks}},
    year = {2014}
}

@misc{Mandlik2021,
      title={Mill.jl and JsonGrinder.jl: automated differentiable feature extraction for learning from raw JSON data},
      author={Simon Mandlik and Matej Racinsky and Viliam Lisy and Tomas Pevny},
      year={2021},
      eprint={2105.09107},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Motivation · Mill.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script data-main="assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" href="assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="assets/themeswap.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="assets/custom.css" rel="stylesheet" type="text/css"/><script data-is-old-version="">document.addEventListener("DOMContentLoaded", function () {
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        document.getElementsByTagName('head')[0].appendChild(meta);
    };

    const div = document.createElement('div');
    div.setAttribute('style', 'position: fixed; width: 100%; top: 0; left: 0; box-shadow: 0 0 10px rgba(0,0,0,0.3); z-index: 999; background-color: #ffaf9c; color: rgba(0, 0, 0, 0.7); border-bottom: 1px solid #d54625; padding: 10px 35px; text-align: center; font-size: 15px;');
    const closer = document.createElement('div');
    closer.setAttribute('style', 'position: absolute; top: calc(50% - 8px); right: 18px; cursor: pointer; width: 12px;');
    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This is an old version of the documentation. <br> <a href="' + href + '" style="color: rgb(46, 99, 184)">Go to the newest version</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
});
</script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href=""><img alt="Mill.jl logo" src="assets/logo.svg"/></a><form action="search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><span class="tocitem">Home</span><ul><li class="is-active"><a class="tocitem" href="">Motivation</a><ul class="internal"><li><a class="tocitem" href="#What-is-a-Multiple-instance-learning-problem?"><span>What is a Multiple instance learning problem?</span></a></li><li><a class="tocitem" href="#Hierarchical-Multiple-Instance-Learning"><span>Hierarchical Multiple Instance Learning</span></a></li><li><a class="tocitem" href="#Relation-to-Graph-Neural-Networks"><span>Relation to Graph Neural Networks</span></a></li><li><a class="tocitem" href="#Difference-to-sequences"><span>Difference to sequences</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="examples/simple/">Simple</a></li><li><a class="tocitem" href="examples/advanced/">Advanced</a></li><li><a class="tocitem" href="examples/graphs/">GNN in 16 lines</a></li><li><a class="tocitem" href="examples/dag/">DAGs</a></li></ul></li><li><span class="tocitem">Architecture of Mill</span><ul><li><a class="tocitem" href="architecture/overview/">Overview</a></li><li><a class="tocitem" href="architecture/reflectin/">ReflectInModel</a></li><li><a class="tocitem" href="architecture/strings/">Handling strings</a></li><li><a class="tocitem" href="architecture/aggregation/">Aggregations</a></li><li><a class="tocitem" href="architecture/missing/">Missing values</a></li><li><a class="tocitem" href="architecture/custom/">Custom Nodes</a></li></ul></li><li><span class="tocitem">Helper tools</span><ul><li><a class="tocitem" href="tools/hierarchical/">HierarichalUtils.jl</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Home</a></li><li class="is-active"><a href="">Motivation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Motivation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pevnak/Mill.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><p><code>Mill.jl</code> is a library built on top of <a href="https://fluxml.ai"><code>Flux.jl</code></a> aimed to flexibly prototype <em>hierarchical multi-instance learning</em> models as described in <a href="#Pevny2018a">Tomáš Pevný , Petr Somol  (2017)</a> and  <a href="#Pevny2018b">Tomáš Pevný , Petr Somol  (2016)</a>.</p><p>TODO table of contents</p><h1 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h1><p>In this section, we provide a short introduction into (Hierarchical) Multi instance learning. A much more detailed overview of this subject can be found in <a href="#Mandlik2020">Šimon Mandlík  (2020)</a>.</p><h2 id="What-is-a-Multiple-instance-learning-problem?"><a class="docs-heading-anchor" href="#What-is-a-Multiple-instance-learning-problem?">What is a Multiple instance learning problem?</a><a id="What-is-a-Multiple-instance-learning-problem?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-Multiple-instance-learning-problem?" title="Permalink"></a></h2><p>In <em>Multiple Instance Learning</em> (MIL), also <em>Multi-Instance Learning</em>, the sample <span>$\bm{x}$</span> is a <em>set of vectors</em> (or matrices) <span>$\{x_1,\ldots,x_l\}$</span>, where <span>$x_i \in \mathbb{R}^d$</span>. As a result, order does not matter, which makes MIL problems different from sequences. In MIL parlance, sample <span>$\bm{x}$</span> is also called <em>a bag</em> and its elements <span>$x_1, \ldots, x_2$</span><em>instances</em>. MIL problems have been introduced in <a href="#Dietterich1997">Thomas G. Dietterich , Richard H. Lathrop , Tomás Lozano-Pérez  (1997)</a>, and extended and generalized in a series of works <a href="#Pevny2018a">Tomáš Pevný , Petr Somol  (2017)</a>, <a href="#Pevny2018b">Tomáš Pevný , Petr Somol  (2016)</a>, <a href="#Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019)</a>. The most comprehensive introduction known to authors is <a href="#Mandlik2020">Šimon Mandlík  (2020)</a>.</p><p>Why are MIL problems relevant? Since the seminal paper from <a href="#Fisher1936">Ronald A Fisher  (1936)</a>, the majority of machine learning problems deals with problems like the one shown below:<sup class="footnote-reference"><a href="#footnote-1" id="citeref-1">[1]</a></sup></p><p><img alt="" src="assets/iris.svg"/></p><p>where the input sample <span>$\bm{x}$</span> is a <em>vector</em> (or generally speaking any <em>tensor</em>) of a fixed dimension containing various measurements of the specimen.</p><p>Most of the time, a skilled botanist is able to identify a specimen not by making use of any measuring device, but by visual or tactile inspection of its stem, leaves and blooms. For different species, different parts of the flower may need to be examined for indicators. At the same time, many species may have nearly identical-looking leaves or blooms, therefore, one needs to step back, consider the whole picture, and appropriately combine lower-level observations into high-level conclusions about the given specimen.</p><p>If we want to use such more elaborate description of the Iris flower using fixed size structures, we will have a hard time, because every specimen can have a different amounts of leaves or blooms (or they may be completely missing). This means that to use the usual <em>fixed dimension</em> paradigm, we have to either somehow select a single leaf (blossom) and extract features from them, or design procedures for aggregating such features over whole sets, so that the output has fixed dimension. This is clearly undesirable. <code>Mill.jl</code> a framework that seamlessly deals with these challenges in data representation.</p><h2 id="Hierarchical-Multiple-Instance-Learning"><a class="docs-heading-anchor" href="#Hierarchical-Multiple-Instance-Learning">Hierarchical Multiple Instance Learning</a><a id="Hierarchical-Multiple-Instance-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Hierarchical-Multiple-Instance-Learning" title="Permalink"></a></h2><p>In <em>Hierarchical Multiple Instance Learning</em> (HMIL) the input may consists of not only sets, but also <em>sets of sets</em> and <a href="https://en.wikipedia.org/wiki/Cartesian_product"><em>Cartesian Products</em></a> of these structures. Returning to the previous Iris flower example, a specimen can be represented like this for HMIL:</p><p><img alt="" src="assets/iris2.svg"/></p><p>The only stem is represented by vector <span>$\bm{x}_s$</span> encoding its distinctive properties such as shape, color, structure or texture. Next, we inspect all blooms. Each of the blooms may have distinctive discriminative signs, therefore, we describe all three in vectors <span>$\bm{x}_{b_1}, \bm{x}_{b_2}, \bm{x}_{b_3}$</span>, one vector for each bloom, and group them to a set. Finally, <span>$\bm{x}_u$</span> represents the only flower which has not blossomed. Likewise, we could describe all leaves of the specimen if any were present. Here we assume that each specimen of the considered species has only one stem, but may have multiple flowers or leaves. Hence, all blooms and buds are represented as unordered sets of vectors as opposed to stem representation, which consists of only one vector.</p><p>How does MIL models cope with variability in numbers of flowers and leaves? Each MIL model consists of two feed-forward neural networks with an element-wise aggregation operator like <code>mean</code> (or <code>maximum</code>) sandwiched between them. Denoting those feed-forward networks (FFNs) as <span>$f_1$</span> and <span>$f_2$</span>, the output of the model applied to a bag is calculated for example as <span>$f_2 \left\(\frac{1}{l}\sum_{i=1}^l f_1(x_i) \right\)$</span> if we use <code>mean</code> as an aggregation function.</p><p>The HMIL model corresponding to the Iris example above would comprise two FFNs and an aggregation to convert set of leafs to a single vector, and another two FFNs and an aggregation to convert set of blossoms to a single vector. These two outputs would be concatenated with a description of a stem, which would be fed to yet another FFN providing the final output. Since the whole scheme is differentiable, we can compute gradients and use any available gradient-based method to optimize the whole model at once using only labels on the level of output<sup class="footnote-reference"><a href="#footnote-2" id="citeref-2">[2]</a></sup>.</p><p>The <code>Mill.jl</code> library simplifies implementation of machine learning problems using (H)MIL representation. In theory, it can represent any problem that can be represented in JSONs. That is why we have created a separate tool, <a href="https://github.com/pevnak/JsonGrinder.jl"><code>JsonGrinder.jl</code></a>, which helps with processing JSON documents for learning.</p><p>In <a href="#Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019)</a>, authors have further extended the <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal approximation theorem</a> to MIL problems, their Cartesian products, and nested MIL problems, i.e. a case where instances of one bag are in fact bags again.</p><h2 id="Relation-to-Graph-Neural-Networks"><a class="docs-heading-anchor" href="#Relation-to-Graph-Neural-Networks">Relation to Graph Neural Networks</a><a id="Relation-to-Graph-Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Relation-to-Graph-Neural-Networks" title="Permalink"></a></h2><p>HMIL problems can be seen as a special subset of general graphs. They differ in two important ways:</p><ul><li>In general graphs, vertices are of a small number of semantic type, whereas in HMIL problems, the number of semantic types of vertices is much higher (it is helpful to think about HMIL problems as about those for which JSON is a natural representation).</li><li>The computational graph of HMIL is a <strong>tree</strong>, which introduces assumption that there exist an efficient inference. Contrary, in general graphs (with loops) there is no efficient inference and one has to resort to message passing (Loopy belief propagation).</li><li>One update message in <strong>loopy belief propagation</strong> can be viewed as a MIL problem, as it has to produce a vector based on infomation inthe neighborhood, which can contain arbitrary number of vertices.</li></ul><h2 id="Difference-to-sequences"><a class="docs-heading-anchor" href="#Difference-to-sequences">Difference to sequences</a><a id="Difference-to-sequences-1"></a><a class="docs-heading-anchor-permalink" href="#Difference-to-sequences" title="Permalink"></a></h2><p>The major difference is that instances in bag are not ordered in any way. This means that if a sequence <span>$(a,b,c)$</span> should be treated as a set, then the output of a function <code>f</code> should be the same for any permutation, i.e. <span>$f(abc) = f(cba) = f(bac) = \ldots$</span>. This property has a dramatic implication on the computational complexity. Sequences are typically modeled using Recurrent Neural Networks (RNNs), where the output is calculated as <span>$f(abc) = g(a, g(b, g(c)))$</span> (slightly abusing the notation). During optimization, a gradient of <span>$g$</span> needs to be calculated recursively, giving raise to infamous vanishing / exploding gradient problems. In constrast, (H)MIL models calculate the output as <span>$f(\frac{1}{3}(g(a) + g(b) + g(c)))$</span> (slightly abusing notation again), which means that the gradient of <span>$g$</span> can be calculated in parallel and not recurrently. </p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><dl><dt>Fisher1936</dt><dd><div id="Fisher1936">Ronald A Fisher  (1936), <a href="">The use of multiple measurements in taxonomic problems</a>, Annals of eugenics, 7(2), 179--188, 1936.
</div></dd><dt>Pevny2018a</dt><dd><div id="Pevny2018a">Tomáš Pevný , Petr Somol  (2017), <a href="https://arxiv.org/abs/1703.02868">Discriminative models for multi-instance problems with tree-structure</a>, arXiv:1703.02868 [].
</div></dd><dt>Pevny2018b</dt><dd><div id="Pevny2018b">Tomáš Pevný , Petr Somol  (2016), <a href="https://arxiv.org/abs/1609.07257">Using Neural Network Formalism to Solve Multiple-Instance Problems</a>, arXiv:1609.07257 [].
</div></dd><dt>Dietterich1997</dt><dd><div id="Dietterich1997">Thomas G. Dietterich , Richard H. Lathrop , Tomás Lozano-Pérez  (1997), <a href="https://doi.org/https://doi.org/10.1016/S0004-3702(96)00034-3">Solving the multiple instance problem with axis-parallel rectangles</a>, Artificial Intelligence, 89(1), 31 - 71, 1997.
</div></dd><dt>Zaheer2018</dt><dd><div id="Zaheer2018">Manzil Zaheer , Satwik Kottur , Siamak Ravanbakhsh , Barnabás Póczos , Ruslan Salakhutdinov , Alexander J. Smola  (2017), <a href="https://arxiv.org/abs/1703.06114">Deep Sets</a>, arXiv:1703.06114 [].
</div></dd><dt>Mandlik2020</dt><dd><div id="Mandlik2020">Šimon Mandlík  (2020), <a href="">Mapping the Internet: Modelling Entity Interactions in Complex Heterogeneous Networks</a>, Master's thesis, Czech Technical University, 2020.
</div></dd><dt>Pevny2019</dt><dd><div id="Pevny2019">Tomáš Pevný , Vojtěch Kovařík  (2019), <a href="https://arxiv.org/abs/1906.00764">Approximation capability of neural networks on spaces of probability measures and tree-structured domains</a>, arXiv:1906.00764 [].
</div></dd></dl><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"><em>Iris</em> flower data set</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Some methods for MIL problems require instance-level labels as well, which are not always available.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="examples/simple/">Simple »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 15 December 2020 16:11">Tuesday 15 December 2020</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>